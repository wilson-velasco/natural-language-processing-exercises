{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92396fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52889bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf688bb",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "1) Define a function named `basic_clean`. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8160a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a954fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f40d7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdős and george pólya were influential hungarian mathematicians who contributed a lot to the field. erdős's name contains the hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as erdos or erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_string = string.lower()\n",
    "lower_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c021efb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field. erdos's name contains the hungarian letter 'o' ('o' with double acute accent), but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_string = unicodedata.normalize('NFKD', lower_string)\\\n",
    ".encode('ascii', 'ignore')\\\n",
    ".decode('utf-8', 'ignore')\n",
    "\n",
    "normal_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4545af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos s name contains the hungarian letter  o   o  with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_no_chars_string = re.sub(r'[^a-z0-9\\s]', '', normal_string.replace(\"'\", \" \"))\n",
    "\n",
    "normal_no_chars_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c164227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    lower_string = string.lower()\n",
    "    \n",
    "    normal_string = unicodedata.normalize('NFKD', lower_string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    \n",
    "    normal_no_chars_string = re.sub(r'[^a-z0-9\\s]', '', normal_string.replace(\"'\", \" \"))\n",
    "    \n",
    "    return normal_no_chars_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6109147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4232042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos s name contains the hungarian letter  o   o  with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string = basic_clean(string)\n",
    "\n",
    "clean_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823daf7",
   "metadata": {},
   "source": [
    "2) Define a function named `tokenize`. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46beea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d92f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos s name contains the hungarian letter o o with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.tokenize(clean_string, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c0d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    ttt = ToktokTokenizer()\n",
    "    return ttt.tokenize(string, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89972d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos s name contains the hungarian letter o o with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(clean_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c16e7",
   "metadata": {},
   "source": [
    "3) Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5efecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "stems = [ps.stem(word) for word in clean_string.split()]\n",
    "stemmed_string = ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12502ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdo and georg polya were influenti hungarian mathematician who contribut a lot to the field erdo s name contain the hungarian letter o o with doubl acut accent but is often incorrectli written as erdo or erdo either by mistak or out of typograph necess'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e77ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    \n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "\n",
    "    stemmed_string = ' '.join(stems)\n",
    "    \n",
    "    return stemmed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f962fdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdo and georg polya were influenti hungarian mathematician who contribut a lot to the field erdo s name contain the hungarian letter o o with doubl acut accent but is often incorrectli written as erdo or erdo either by mistak or out of typograph necess'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(clean_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2c1c6a",
   "metadata": {},
   "source": [
    "4) Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e04ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0a09e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematician who contributed a lot to the field erdos s name contains the hungarian letter o o with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in clean_string.split()]\n",
    "\n",
    "lemmed_string = ' '.join(lemmas)\n",
    "\n",
    "lemmed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf939455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    \n",
    "    lemmed_string = ' '.join(lemmas)\n",
    "    \n",
    "    return lemmed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32ba654",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed_string = lemmatize(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eadd7904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos and george polya were influential hungarian mathematician who contributed a lot to the field erdos s name contains the hungarian letter o o with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c050c",
   "metadata": {},
   "source": [
    "5) Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, `extra_words` and `exclude_words`. These parameters should define any additional stop words to include, and any words that we *don't* want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad364d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38fc7a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = []\n",
    "\n",
    "to_add = []\n",
    "\n",
    "stopword_list = [word for word in stopword_list if word not in to_remove]\n",
    "\n",
    "for word in to_add:\n",
    "    stopword_list.append(word)\n",
    "\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b5528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae37e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words=[], exclude_words=[]):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    #Removing words from list\n",
    "    stopword_list = [word for word in stopword_list if word not in exclude_words]\n",
    "    \n",
    "    #Adding words to list\n",
    "    \n",
    "    for word in extra_words:\n",
    "        stopword_list.append(word)\n",
    "    \n",
    "    no_stop_words = [word for word in string.split() if word not in stopword_list]\n",
    "    \n",
    "    no_stop_string = ' '.join(no_stop_words)\n",
    "    \n",
    "    return no_stop_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce485fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos george polya hungarian mathematician contributed lot field erdos name contains hungarian letter double acute accent often written erdos erdos either by mistake typographical necessity'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check with adding and removing certain words. Won't do it for the actual string\n",
    "\n",
    "remove_stopwords(lemmed_string, ['influential', 'incorrectly'], ['by'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a927223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paul erdos george polya influential hungarian mathematician contributed lot field erdos name contains hungarian letter double acute accent often incorrectly written erdos erdos either mistake typographical necessity'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_string = remove_stopwords(lemmed_string)\n",
    "\n",
    "parsed_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad136302",
   "metadata": {},
   "source": [
    "6) Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe `news_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef740883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensex, Nifty end at fresh closing highs</td>\n",
       "      <td>Benchmark indices Sensex and Nifty ended at re...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon tricked millions of customers into enro...</td>\n",
       "      <td>US Federal Trade Commission (FTC) has sued Ama...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIME releases list of the world's 100 most inf...</td>\n",
       "      <td>TIME magazine has released its annual list of ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which are the world's top 10 airlines accordin...</td>\n",
       "      <td>Singapore Airlines is the world's best airline...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grab lays off over 1,000 employees</td>\n",
       "      <td>Singapore-based ride-hailing and food delivery...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Richard Gere attends Yoga event led by PM Modi...</td>\n",
       "      <td>Actor Richard Gere was in attendance at the Yo...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Parents said 'Even cats, dogs are on TV, when ...</td>\n",
       "      <td>Nawazuddin Siddiqui, while talking about his r...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Thought kids at school would laugh at me, said...</td>\n",
       "      <td>Jugal Hansraj said that he had initially rejec...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Asked Alia 'What is it that H'wood has', she s...</td>\n",
       "      <td>Filmmaker Mahesh Bhatt said he once asked Alia...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rajamouli said Baahubali was litmus test for M...</td>\n",
       "      <td>SS Rajamouli's father and writer Vijayendra Pr...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0            Sensex, Nifty end at fresh closing highs   \n",
       "1   Amazon tricked millions of customers into enro...   \n",
       "2   TIME releases list of the world's 100 most inf...   \n",
       "3   Which are the world's top 10 airlines accordin...   \n",
       "4                  Grab lays off over 1,000 employees   \n",
       "..                                                ...   \n",
       "95  Richard Gere attends Yoga event led by PM Modi...   \n",
       "96  Parents said 'Even cats, dogs are on TV, when ...   \n",
       "97  Thought kids at school would laugh at me, said...   \n",
       "98  Asked Alia 'What is it that H'wood has', she s...   \n",
       "99  Rajamouli said Baahubali was litmus test for M...   \n",
       "\n",
       "                                              content       category  \n",
       "0   Benchmark indices Sensex and Nifty ended at re...       business  \n",
       "1   US Federal Trade Commission (FTC) has sued Ama...       business  \n",
       "2   TIME magazine has released its annual list of ...       business  \n",
       "3   Singapore Airlines is the world's best airline...       business  \n",
       "4   Singapore-based ride-hailing and food delivery...       business  \n",
       "..                                                ...            ...  \n",
       "95  Actor Richard Gere was in attendance at the Yo...  entertainment  \n",
       "96  Nawazuddin Siddiqui, while talking about his r...  entertainment  \n",
       "97  Jugal Hansraj said that he had initially rejec...  entertainment  \n",
       "98  Filmmaker Mahesh Bhatt said he once asked Alia...  entertainment  \n",
       "99  SS Rajamouli's father and writer Vijayendra Pr...  entertainment  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame(acquire.get_news_articles())\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262dbe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business         25\n",
       "sports           25\n",
       "technology       25\n",
       "entertainment    25\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49264c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17539e35",
   "metadata": {},
   "source": [
    "7) Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4493f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://codeup.com/featured/apida-heritage-month/'\n",
    "       ,'https://codeup.com/featured/women-in-tech-panelist-spotlight/'\n",
    "       ,'https://codeup.com/events/black-excellence-in-tech-panelist-spotlight-stephanie-jones/'\n",
    "       ,'https://codeup.com/codeup-news/codeup-best-bootcamps/'\n",
    "       ,'https://codeup.com/employers/hiring-tech-talent/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee0091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://codeup.com/featured/apida-heritage-month/</td>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://codeup.com/featured/women-in-tech-pane...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://codeup.com/events/black-excellence-in-...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight -...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://codeup.com/codeup-news/codeup-best-boo...</td>\n",
       "      <td>Codeup Among Top 58 Best Coding Bootcamps of 2...</td>\n",
       "      <td>Codeup is pleased to announce we have been ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://codeup.com/employers/hiring-tech-talent/</td>\n",
       "      <td>Hiring Tech Talent Around the Holidays - Codeup</td>\n",
       "      <td>Are you a hiring manager having trouble filli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://codeup.com/featured/apida-heritage-month/   \n",
       "1  https://codeup.com/featured/women-in-tech-pane...   \n",
       "2  https://codeup.com/events/black-excellence-in-...   \n",
       "3  https://codeup.com/codeup-news/codeup-best-boo...   \n",
       "4   https://codeup.com/employers/hiring-tech-talent/   \n",
       "\n",
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Black excellence in tech: Panelist Spotlight -...   \n",
       "3  Codeup Among Top 58 Best Coding Bootcamps of 2...   \n",
       "4    Hiring Tech Talent Around the Holidays - Codeup   \n",
       "\n",
       "                                             content  \n",
       "0   May is traditionally known as Asian American ...  \n",
       "1   Women in tech: Panelist Spotlight – Magdalena...  \n",
       "2   Black excellence in tech: Panelist Spotlight ...  \n",
       "3   Codeup is pleased to announce we have been ra...  \n",
       "4   Are you a hiring manager having trouble filli...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = pd.DataFrame(acquire.get_blog_articles(urls))\n",
    "\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04fd53",
   "metadata": {},
   "source": [
    "8) For each dataframe, produce the following columns:\n",
    "\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "703e7691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensex, Nifty end at fresh closing highs</td>\n",
       "      <td>Benchmark indices Sensex and Nifty ended at re...</td>\n",
       "      <td>benchmark indices sensex nifty ended record cl...</td>\n",
       "      <td>benchmark indic sensex nifti end record close ...</td>\n",
       "      <td>benchmark index sensex nifty ended record clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon tricked millions of customers into enro...</td>\n",
       "      <td>US Federal Trade Commission (FTC) has sued Ama...</td>\n",
       "      <td>us federal trade commission ftc sued amazon ac...</td>\n",
       "      <td>us feder trade commiss ftc su amazon accus tri...</td>\n",
       "      <td>u federal trade commission ftc sued amazon acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TIME releases list of the world's 100 most inf...</td>\n",
       "      <td>TIME magazine has released its annual list of ...</td>\n",
       "      <td>time magazine released annual list world 100 i...</td>\n",
       "      <td>time magazin releas annual list world 100 infl...</td>\n",
       "      <td>time magazine released annual list world 100 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which are the world's top 10 airlines accordin...</td>\n",
       "      <td>Singapore Airlines is the world's best airline...</td>\n",
       "      <td>singapore airlines world best airline accordin...</td>\n",
       "      <td>singapor airlin world best airlin accord skytr...</td>\n",
       "      <td>singapore airline world best airline according...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grab lays off over 1,000 employees</td>\n",
       "      <td>Singapore-based ride-hailing and food delivery...</td>\n",
       "      <td>singaporebased ridehailing food delivery app g...</td>\n",
       "      <td>singaporebas ridehail food deliveri app grab l...</td>\n",
       "      <td>singaporebased ridehailing food delivery app g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Richard Gere attends Yoga event led by PM Modi...</td>\n",
       "      <td>Actor Richard Gere was in attendance at the Yo...</td>\n",
       "      <td>actor richard gere attendance yoga event led p...</td>\n",
       "      <td>actor richard gere attend yoga event led pm na...</td>\n",
       "      <td>actor richard gere attendance yoga event led p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Parents said 'Even cats, dogs are on TV, when ...</td>\n",
       "      <td>Nawazuddin Siddiqui, while talking about his r...</td>\n",
       "      <td>nawazuddin siddiqui talking role junior artist...</td>\n",
       "      <td>nawazuddin siddiqui talk role junior artist ti...</td>\n",
       "      <td>nawazuddin siddiqui talking role junior artist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Thought kids at school would laugh at me, said...</td>\n",
       "      <td>Jugal Hansraj said that he had initially rejec...</td>\n",
       "      <td>jugal hansraj said initially rejected shekhar ...</td>\n",
       "      <td>jugal hansraj said initi reject shekhar kapur ...</td>\n",
       "      <td>jugal hansraj said initially rejected shekhar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Asked Alia 'What is it that H'wood has', she s...</td>\n",
       "      <td>Filmmaker Mahesh Bhatt said he once asked Alia...</td>\n",
       "      <td>filmmaker mahesh bhatt said asked alia bhatt h...</td>\n",
       "      <td>filmmak mahesh bhatt said ask alia bhatt holly...</td>\n",
       "      <td>filmmaker mahesh bhatt said asked alia bhatt h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rajamouli said Baahubali was litmus test for M...</td>\n",
       "      <td>SS Rajamouli's father and writer Vijayendra Pr...</td>\n",
       "      <td>ss rajamouli father writer vijayendra prasad s...</td>\n",
       "      <td>ss rajamouli father writer vijayendra prasad s...</td>\n",
       "      <td>s rajamouli father writer vijayendra prasad sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0            Sensex, Nifty end at fresh closing highs   \n",
       "1   Amazon tricked millions of customers into enro...   \n",
       "2   TIME releases list of the world's 100 most inf...   \n",
       "3   Which are the world's top 10 airlines accordin...   \n",
       "4                  Grab lays off over 1,000 employees   \n",
       "..                                                ...   \n",
       "95  Richard Gere attends Yoga event led by PM Modi...   \n",
       "96  Parents said 'Even cats, dogs are on TV, when ...   \n",
       "97  Thought kids at school would laugh at me, said...   \n",
       "98  Asked Alia 'What is it that H'wood has', she s...   \n",
       "99  Rajamouli said Baahubali was litmus test for M...   \n",
       "\n",
       "                                             original  \\\n",
       "0   Benchmark indices Sensex and Nifty ended at re...   \n",
       "1   US Federal Trade Commission (FTC) has sued Ama...   \n",
       "2   TIME magazine has released its annual list of ...   \n",
       "3   Singapore Airlines is the world's best airline...   \n",
       "4   Singapore-based ride-hailing and food delivery...   \n",
       "..                                                ...   \n",
       "95  Actor Richard Gere was in attendance at the Yo...   \n",
       "96  Nawazuddin Siddiqui, while talking about his r...   \n",
       "97  Jugal Hansraj said that he had initially rejec...   \n",
       "98  Filmmaker Mahesh Bhatt said he once asked Alia...   \n",
       "99  SS Rajamouli's father and writer Vijayendra Pr...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   benchmark indices sensex nifty ended record cl...   \n",
       "1   us federal trade commission ftc sued amazon ac...   \n",
       "2   time magazine released annual list world 100 i...   \n",
       "3   singapore airlines world best airline accordin...   \n",
       "4   singaporebased ridehailing food delivery app g...   \n",
       "..                                                ...   \n",
       "95  actor richard gere attendance yoga event led p...   \n",
       "96  nawazuddin siddiqui talking role junior artist...   \n",
       "97  jugal hansraj said initially rejected shekhar ...   \n",
       "98  filmmaker mahesh bhatt said asked alia bhatt h...   \n",
       "99  ss rajamouli father writer vijayendra prasad s...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   benchmark indic sensex nifti end record close ...   \n",
       "1   us feder trade commiss ftc su amazon accus tri...   \n",
       "2   time magazin releas annual list world 100 infl...   \n",
       "3   singapor airlin world best airlin accord skytr...   \n",
       "4   singaporebas ridehail food deliveri app grab l...   \n",
       "..                                                ...   \n",
       "95  actor richard gere attend yoga event led pm na...   \n",
       "96  nawazuddin siddiqui talk role junior artist ti...   \n",
       "97  jugal hansraj said initi reject shekhar kapur ...   \n",
       "98  filmmak mahesh bhatt said ask alia bhatt holly...   \n",
       "99  ss rajamouli father writer vijayendra prasad s...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   benchmark index sensex nifty ended record clos...  \n",
       "1   u federal trade commission ftc sued amazon acc...  \n",
       "2   time magazine released annual list world 100 i...  \n",
       "3   singapore airline world best airline according...  \n",
       "4   singaporebased ridehailing food delivery app g...  \n",
       "..                                                ...  \n",
       "95  actor richard gere attendance yoga event led p...  \n",
       "96  nawazuddin siddiqui talking role junior artist...  \n",
       "97  jugal hansraj said initially rejected shekhar ...  \n",
       "98  filmmaker mahesh bhatt said asked alia bhatt h...  \n",
       "99  s rajamouli father writer vijayendra prasad sh...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_nlp = pd.DataFrame()\n",
    "\n",
    "news_df_nlp['title'] = news_df['title']\n",
    "news_df_nlp['original'] = news_df['content']\n",
    "news_df_nlp['clean'] = [remove_stopwords(tokenize(basic_clean(string))) for string in news_df.content]\n",
    "news_df_nlp['stemmed'] = [stem(string) for string in news_df_nlp.clean]\n",
    "news_df_nlp['lemmatized'] = [lemmatize(string) for string in news_df_nlp.clean]\n",
    "\n",
    "news_df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ee599d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotlight on APIDA Voices: Celebrating Heritag...</td>\n",
       "      <td>May is traditionally known as Asian American ...</td>\n",
       "      <td>may traditionally known asian american pacific...</td>\n",
       "      <td>may tradit known asian american pacif island a...</td>\n",
       "      <td>may traditionally known asian american pacific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena ...</td>\n",
       "      <td>Women in tech: Panelist Spotlight – Magdalena...</td>\n",
       "      <td>women tech panelist spotlight magdalena rahn c...</td>\n",
       "      <td>women tech panelist spotlight magdalena rahn c...</td>\n",
       "      <td>woman tech panelist spotlight magdalena rahn c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight -...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight ...</td>\n",
       "      <td>black excellence tech panelist spotlight steph...</td>\n",
       "      <td>black excel tech panelist spotlight stephani j...</td>\n",
       "      <td>black excellence tech panelist spotlight steph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Among Top 58 Best Coding Bootcamps of 2...</td>\n",
       "      <td>Codeup is pleased to announce we have been ra...</td>\n",
       "      <td>codeup pleased announce ranked among 58 best c...</td>\n",
       "      <td>codeup pleas announc rank among 58 best code b...</td>\n",
       "      <td>codeup pleased announce ranked among 58 best c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring Tech Talent Around the Holidays - Codeup</td>\n",
       "      <td>Are you a hiring manager having trouble filli...</td>\n",
       "      <td>hiring manager trouble filling position around...</td>\n",
       "      <td>hire manag troubl fill posit around holiday co...</td>\n",
       "      <td>hiring manager trouble filling position around...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Spotlight on APIDA Voices: Celebrating Heritag...   \n",
       "1  Women in tech: Panelist Spotlight – Magdalena ...   \n",
       "2  Black excellence in tech: Panelist Spotlight -...   \n",
       "3  Codeup Among Top 58 Best Coding Bootcamps of 2...   \n",
       "4    Hiring Tech Talent Around the Holidays - Codeup   \n",
       "\n",
       "                                            original  \\\n",
       "0   May is traditionally known as Asian American ...   \n",
       "1   Women in tech: Panelist Spotlight – Magdalena...   \n",
       "2   Black excellence in tech: Panelist Spotlight ...   \n",
       "3   Codeup is pleased to announce we have been ra...   \n",
       "4   Are you a hiring manager having trouble filli...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  may traditionally known asian american pacific...   \n",
       "1  women tech panelist spotlight magdalena rahn c...   \n",
       "2  black excellence tech panelist spotlight steph...   \n",
       "3  codeup pleased announce ranked among 58 best c...   \n",
       "4  hiring manager trouble filling position around...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  may tradit known asian american pacif island a...   \n",
       "1  women tech panelist spotlight magdalena rahn c...   \n",
       "2  black excel tech panelist spotlight stephani j...   \n",
       "3  codeup pleas announc rank among 58 best code b...   \n",
       "4  hire manag troubl fill posit around holiday co...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  may traditionally known asian american pacific...  \n",
       "1  woman tech panelist spotlight magdalena rahn c...  \n",
       "2  black excellence tech panelist spotlight steph...  \n",
       "3  codeup pleased announce ranked among 58 best c...  \n",
       "4  hiring manager trouble filling position around...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df_nlp = pd.DataFrame()\n",
    "\n",
    "codeup_df_nlp['title'] = codeup_df['title']\n",
    "codeup_df_nlp['original'] = codeup_df['content']\n",
    "codeup_df_nlp['clean'] = [remove_stopwords(tokenize(basic_clean(string))) for string in codeup_df.content]\n",
    "codeup_df_nlp['stemmed'] = [stem(string) for string in codeup_df_nlp.clean]\n",
    "codeup_df_nlp['lemmatized'] = [lemmatize(string) for string in codeup_df_nlp.clean]\n",
    "\n",
    "codeup_df_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc11972",
   "metadata": {},
   "source": [
    "9) Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text? Lemmatized text.\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text? Lemmatized text.\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text? In this instance, given the huge amount, only then would I use stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96b8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
